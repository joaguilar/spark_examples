{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9698d0be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/spark-3.5.1-bin-hadoop3')\n",
    "from pyspark import *\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DateType, TimestampType, LongType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType, DecimalType\n",
    "from pyspark.sql.functions import regexp_extract, split, from_unixtime, col, avg, min, max, desc\n",
    "from pyspark.sql.functions import grouping, explode, array_contains\n",
    "from pyspark.sql.functions import mean, stddev, skewness, kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"analytics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bdfed9",
   "metadata": {},
   "source": [
    "# Arboles de Decisión\n",
    "\n",
    "## Entrenamiento\n",
    "\n",
    "### Generación de Datos\n",
    "\n",
    "Primero generamos un conjunto de datos aleatorios que usaria Spark para entrenar el arbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos\n",
    "empleos = [\"admin\", \"tecnico\", \"servicios\", \"gerente\"]\n",
    "educacion = [\"primaria\", \"secundaria\", \"universitaria\"]\n",
    "\n",
    "data = [\n",
    "    Row(edad=random.randint(18, 65),\n",
    "        saldo=random.randint(-500, 5000),\n",
    "        empleo=random.choice(empleos),\n",
    "        educacion=random.choice(educacion),\n",
    "        suscripcion=random.choice([0, 1]))\n",
    "    for _ in range(300)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "\n",
    "# Guardar los datos en CSV\n",
    "df.write.csv(\"datos_banco.csv\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5657123c",
   "metadata": {},
   "source": [
    "## Preparar los datos\n",
    "\n",
    " Utilizamos StringIndexer para convertir las categorías en índices numéricos basados en la frecuencia de cada categoría, asignando los índices más bajos a las categorías más frecuentes.\n",
    "\n",
    "Posteriormente, OneHotEncoder transforma estos índices numéricos en vectores binarios para evitar que el modelo interprete las variables categóricas como si tuvieran un orden o jerarquía. Cada categoría se representa con un vector donde sólo un elemento es '1' y el resto son '0', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c3958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "# Indexar las columnas categóricas\n",
    "indexer = StringIndexer(inputCols=[\"empleo\", \"educacion\"], outputCols=[\"empleo_idx\", \"educacion_idx\"])\n",
    "df_indexed = indexer.fit(df).transform(df)\n",
    "\n",
    "# Aplicar OneHotEncoder a las columnas indexadas\n",
    "encoder = OneHotEncoder(inputCols=[\"empleo_idx\", \"educacion_idx\"], outputCols=[\"empleo_enc\", \"educacion_enc\"])\n",
    "df_encoded = encoder.fit(df_indexed).transform(df_indexed)\n",
    "\n",
    "# Assembler para combinar todas las características en una sola columna de vectores\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"edad\", \"saldo\", \"empleo_enc\", \"educacion_enc\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "df_final = assembler.transform(df_encoded)\n",
    "\n",
    "# Seleccionar las columnas necesarias para el modelo\n",
    "df_model = df_final.select(\"features\", \"suscripcion\")\n",
    "\n",
    "df_model.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830fef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc6990",
   "metadata": {},
   "source": [
    "### Entrenar el modelo de árbol de decisión\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f77711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Crear y entrenar el modelo de árbol de decisión\n",
    "dt = DecisionTreeClassifier(labelCol=\"suscripcion\", featuresCol=\"features\")\n",
    "model = dt.fit(df_model)\n",
    "\n",
    "# Mostrar el árbol de decisión\n",
    "print(\"Árbol de decisión modelado:\")\n",
    "print(model.toDebugString)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24abf71f",
   "metadata": {},
   "source": [
    "## Clasificación\n",
    "\n",
    "### Crear un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6008f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con un ejemplo\n",
    "ejemplo = spark.createDataFrame([\n",
    "    (30, 1500, \"admin\", \"universitaria\"),(30, 1500, \"servicios\", \"secundaria\")\n",
    "], [\"edad\", \"saldo\", \"empleo\", \"educacion\"])\n",
    "\n",
    "# Mostrar el nuevo ejemplo\n",
    "ejemplo.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3034e58a",
   "metadata": {},
   "source": [
    "### Preprocesar el ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d4df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar StringIndexer\n",
    "ejemplo_indexed = indexer.fit(ejemplo).transform(ejemplo)\n",
    "\n",
    "# Aplicar OneHotEncoder\n",
    "ejemplo_encoded = encoder.fit(ejemplo_indexed).transform(ejemplo_indexed)\n",
    "\n",
    "# Aplicar VectorAssembler\n",
    "ejemplo_final = assembler.transform(ejemplo_encoded)\n",
    "\n",
    "# Seleccionar la columna 'features'\n",
    "ejemplo_final = ejemplo_final.select(\"features\")\n",
    "ejemplo_final.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535948fc",
   "metadata": {},
   "source": [
    "### Clasificar el ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba76eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones\n",
    "predicciones = model.transform(ejemplo_final)\n",
    "\n",
    "# Mostrar las predicciones\n",
    "predicciones.select(\"prediction\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
