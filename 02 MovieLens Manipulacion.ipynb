{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce4536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/spark/spark-3.5.1-bin-hadoop3')\n",
    "from pyspark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DateType, TimestampType, LongType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType, DecimalType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e13b20",
   "metadata": {},
   "source": [
    "# Sesion\n",
    "\n",
    "Lo primero siempre es crear la sesion de Spark. La sesion permite a todos los procesos involucrados compartir contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"movielens\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e208eef",
   "metadata": {},
   "source": [
    "# Carga de datos\n",
    "\n",
    "En la siguiente celda realizamos la carga de los datos del dataset de Movielens. en este caso vamos a cargar 3 de las tablas:\n",
    "\n",
    "* ratings\n",
    "* movies\n",
    "* tags\n",
    "\n",
    "Para esto definimos primero los schemas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7700f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsDf = spark.read.csv(\"./ml-latest-small/ratings.csv\")\n",
    "moviesDf = spark.read.csv(\"./ml-latest-small/movies.csv\")\n",
    "tagsDf = spark.read.csv(\"./ml-latest-small/tags.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79230b5",
   "metadata": {},
   "source": [
    "Revisamos primero el dataframe de ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b209b31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratingsDf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907fd49b",
   "metadata": {},
   "source": [
    "Vemos que tiene header, y los tipos de datos, incluyendo el ultimo que es un timestamp. Podemos definir el schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_schema  = StructType(fields=[\n",
    "    StructField(\"userId\",IntegerType(),True), \n",
    "    StructField(\"movieId\",IntegerType(),True),\n",
    "    StructField(\"rating\",DecimalType(precision=2,scale=1),True),\n",
    "    StructField(\"timestamp\",LongType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsDf = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"dateFormat\", \"yyyyMMdd\")\\\n",
    "    .schema(ratings_schema)\\\n",
    "    .csv(\"./ml-latest-small/ratings.csv\")\n",
    "ratingsDf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addbe26f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratingsDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c28853e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_schema  = StructType(fields=[\n",
    "    StructField(\"movieId\",IntegerType(),True), \n",
    "    StructField(\"title\",StringType(),True),\n",
    "    StructField(\"genres\",StringType(),True)\n",
    "])\n",
    "\n",
    "moviesDf = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .schema(movies_schema)\\\n",
    "    .csv(\"./ml-latest-small/movies.csv\")\n",
    "moviesDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89cbca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75b1796",
   "metadata": {},
   "source": [
    "Notamos dos cosas:\n",
    "\n",
    "1. En la columna `genres` vienen multiples valores separados por `|`\n",
    "1. En la columna `title` viene tanto el nombre de la palicula como el año en que salió\n",
    "\n",
    "Queremos separar esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028eef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "\n",
    "# La función spli separa una columna en un arreglo\n",
    "moviesDf.select(split(col(\"genres\"),\"\\|\").alias(\"genresSplit\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c53cab1",
   "metadata": {},
   "source": [
    "O de otra forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a727c8c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDf.withColumn(\"genresSplit\", split(moviesDf[\"genres\"],\"\\|\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace7d6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit = moviesDf.withColumn(\"genresSplit\", split(moviesDf[\"genres\"],\"\\|\"))\n",
    "moviesDfSplit.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100c991d",
   "metadata": {},
   "source": [
    "No es necesario mantener ambas columnas, entonces es posible eliminar la columna `genres`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesDfSplit.drop(\"genres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2b3c65",
   "metadata": {},
   "source": [
    "Ahora revisamos el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesDfSplit.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5485d1",
   "metadata": {},
   "source": [
    "Los dataframes son inmutables, por lo que vimos anteriormente fue un nuevo dataframe. Para conservar el cambio tenemos que asignarlo para ver el cambio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7739c45b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit = moviesDfSplit.drop(\"genres\")\n",
    "moviesDfSplit.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c812ff8a",
   "metadata": {},
   "source": [
    "Ahora sucede lo mismo con la columna title. Podemos extrar el nombre de la película y el año y crear columnas especificas para cada dato. Usamos expresiones regulares con la funcion [regexp_extract](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_extract.html#pyspark.sql.functions.regexp_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9d24e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col\n",
    "\n",
    "moviesDfSplit.withColumn(\"year\", regexp_extract(moviesDf[\"title\"],\"^.+\\(([0-9]+)\\)$\",1)).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc670c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit.withColumn(\"year\", regexp_extract(moviesDf[\"title\"],\"^.+\\(([0-9]+)\\)$\",1)).printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee39340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit.withColumn(\"year\", regexp_extract(moviesDf[\"title\"],\"^.+\\(([0-9]+)\\)$\",1).cast(IntegerType())).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34370b0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit.withColumn(\"year\", regexp_extract(moviesDf[\"title\"],\"^.+\\(([0-9]+)\\)$\",1).cast(IntegerType())).printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesDfSplit = moviesDfSplit\\\n",
    "                .withColumn(\\\n",
    "                            \"year\",\\\n",
    "                            regexp_extract(\\\n",
    "                                           moviesDf[\"title\"],\\\n",
    "                                           \"^.+\\(([0-9]+)\\)$\",\\\n",
    "                                           1)\\\n",
    "                            .cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840e51b7",
   "metadata": {},
   "source": [
    "Existen muchas funciones similares que se pueden utilizar, la documentación está en [Spark SQL Functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a3fe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e786c95",
   "metadata": {},
   "source": [
    "Hacemos lo mismo para obtener el titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d85597",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesDfSplit=moviesDfSplit\\\n",
    "                .withColumn(\\\n",
    "                            \"title_temp\",\\\n",
    "                            regexp_extract(\\\n",
    "                                           _[\"title\"],\\\n",
    "                                           \"^(.+?) \\([0-9]+\\)$\",\\\n",
    "                                           1))\\\n",
    "                .drop('title')\\\n",
    "                .withColumnRenamed(\"title_temp\",\"title\")\n",
    "moviesDfSplit.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43ee32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDfSplit.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18363d06",
   "metadata": {},
   "source": [
    "Por ultimo hacemos lo mismo con la tabla de tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce4237",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_schema  = StructType(fields=[    \n",
    "    StructField(\"userId\",IntegerType(),True), \n",
    "    StructField(\"movieId\",IntegerType(),True), \n",
    "    StructField(\"tag\",StringType(),True),\n",
    "    StructField(\"timestamp\",LongType(),True)\n",
    "])\n",
    "\n",
    "tagsDf = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .schema(tags_schema)\\\n",
    "    .csv(\"./ml-latest-small/tags.csv\")\n",
    "\n",
    "tagsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea29cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagsDf.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c823e78",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87653f98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagsDf.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8904d6",
   "metadata": {},
   "source": [
    "Finalmente, convertimos el timestamp en una fecha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime\n",
    "\n",
    "\n",
    "tags_schema  = StructType(fields=[    \n",
    "    StructField(\"userId\",IntegerType(),True), \n",
    "    StructField(\"movieId\",IntegerType(),True), \n",
    "    StructField(\"tag\",StringType(),True),\n",
    "    StructField(\"timestamp\",LongType(),True)\n",
    "])\n",
    "\n",
    "tagsDf = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .schema(tags_schema)\\\n",
    "    .csv(\"./ml-latest-small/tags.csv\")\n",
    "\n",
    "\n",
    "tagsDf=tagsDf\\\n",
    "        .withColumn(\\\n",
    "            \"date\",\\\n",
    "            from_unixtime(\"timestamp\", \"yyyyMMdd\"))\\\n",
    "                .drop('timestamp')\n",
    "\n",
    "tagsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39714152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
