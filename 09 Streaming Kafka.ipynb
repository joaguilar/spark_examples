{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e794c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kafka-python pyspark\n",
    "\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.13:3.5.1,org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1,org.apache.kafka:kafka-clients:3.5.1 pyspark-shell'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e42db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/spark/spark-3.5.1-bin-hadoop3')\n",
    "from pyspark import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DateType, TimestampType, LongType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType, DecimalType\n",
    "from pyspark.sql.functions import regexp_extract, split, from_unixtime, col, avg, min, max\n",
    "from pyspark.sql.functions import grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "#from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "# Crear el contexto de Spark\n",
    "sc = None\n",
    "try:\n",
    "    sc = SparkContext(appName=\"movielens\")\n",
    "except:\n",
    "    sc = SparkContext.getOrCreate(\"movielens\")\n",
    "ssc = StreamingContext(sc, 10)  # Intervalo de 10 segundos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e0c1f9",
   "metadata": {},
   "source": [
    "# Structured Streaming\n",
    "\n",
    "Para conectarse con Kafka, se utilia un paradigma diferente llamado **Structured Streaming**.\n",
    "\n",
    "Documentación: [Spark Streaming + Kafka Integration Guide](https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html)\n",
    "\n",
    "Mas general, documentación sobre Structured Streaming: [Spark Streaming Programming Guide](https://spark.apache.org/docs/latest/streaming-programming-guide.html) sobre todo la sección de [Basic Concepts](https://spark.apache.org/docs/latest/streaming-programming-guide.html#basic-concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89220b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"movielens\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1,org.apache.kafka:kafka-clients:3.5.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "!spark-submit --class movielens --packages org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1,org.apache.kafka:kafka-clients:3.5.1 09\\ Streaming\\ Kafka.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83849d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema =  StructType([\n",
    "            StructField(\"col1\", StringType()),\n",
    "            StructField(\"col2\", StringType())\n",
    "            ])\n",
    "\n",
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:2181\") \\\n",
    "  .option(\"subscribe\", \"test-topic\") \\\n",
    "  .load()\n",
    "\n",
    "value_df = df.select(col(\"topic\"), col(\"partition\"), col(\"offset\"), from_json(col(\"value\").cast(\"STRING\"), schema).alias(\"values\"))\n",
    "\n",
    "print(value_df)\n",
    "# Conexión a Kafka\n",
    "#kafkaStream = KafkaUtils.createStream(ssc, \"localhost:2181\", \"spark-streaming\", {\"test-topic\": 1})\n",
    "\n",
    "# Extraer solo los mensajes del stream de Kafka\n",
    "#messages = kafkaStream.map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828be782",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c108a",
   "metadata": {},
   "source": [
    "# Envío de mensajes\n",
    "\n",
    "Antes de ejecutar el siguiente código, se puede ejecutar el cliente de consola de Kafka para poder enviarle mensajes. Esto se puede realizar a traves del siguiente comando:\n",
    "\n",
    "```\n",
    "bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test-topic\n",
    "```\n",
    "Y se puede digitar en la consola el mensaje a enviar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar las palabras en los mensajes\n",
    "words = messages.flatMap(lambda line: line.split(\" \"))\n",
    "wordCounts = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Mostrar el conteo de palabras\n",
    "wordCounts.pprint()\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
